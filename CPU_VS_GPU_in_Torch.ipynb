{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Here We are going to use GPU in Notebook "
      ],
      "metadata": {
        "id": "Pl4uUBw0Bad8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_-Mq0XYBVvS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "from matplotlib.colors import to_rgba\n",
        "from torch import Tensor\n",
        "from tqdm.notebook import tqdm  # Progress bar\n",
        "\n",
        "set_matplotlib_formats(\"svg\", \"pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l85Bz0ZhBYxx",
        "outputId": "8e40daa0-ca29-4f0a-ef98-12c6afb0af75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"CPU\")\n",
        "print(\"Device\" , device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SilMAZ6BxfO",
        "outputId": "931fd3cf-2acf-45ab-df13-348bf47ea06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CPU VS GPU Time Comparison\n"
      ],
      "metadata": {
        "id": "b4XTtgGyJmEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch.randn() it gives random integers having mean 0 and variance 1\n",
        "x = torch.randn(5000,5000)"
      ],
      "metadata": {
        "id": "dTcqpuBZJANV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU Version\n",
        "\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x,x)\n",
        "end_time = time.time()\n",
        "print(\"CPU Time : \" , (end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJAcRdG2M710",
        "outputId": "351de404-da8f-4d21-bfa1-6ec95c846e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time :  2.0376977920532227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU Version\n",
        "if torch.cuda.is_available():\n",
        "  x = x.to(device)\n",
        "  # Cuda is asynchronous so\n",
        "  start = torch.cuda.Event(enable_timing = True)\n",
        "  end = torch.cuda.Event(enable_timing = True)\n",
        "  start.record()\n",
        "  _ = torch.matmul(x,x)\n",
        "  end.record()\n",
        "  torch.cuda.synchronize() # Wait for all kernal to complete\n",
        "  print(\"GPU Time : \" , 0.001*start.elapsed_time(end)) # Muliply with 0.001 because by default cuda count in miliseconds so convert it in seconds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YQ_LWNNOfMg",
        "outputId": "aa646c81-8b35-4308-98ca-acd8ab7ecdc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Time :  0.08779769897460937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***So from above experiment it is cleared that GPU takes less time than CPU for executing functions***"
      ],
      "metadata": {
        "id": "ZiHB2W4lRdAe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ZdeEw-jRa4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}